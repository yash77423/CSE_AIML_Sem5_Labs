{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c83717b",
   "metadata": {},
   "source": [
    "1. Load a Dataset into a PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b6463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/31 14:37:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      2|   3.0|964981247|\n",
      "|     1|      3|   5.0|964982224|\n",
      "|     2|      1|   5.0|964982821|\n",
      "|     2|      2|   4.0|964983034|\n",
      "|     2|      4|   2.0|964982564|\n",
      "|     3|      2|   4.0|964982274|\n",
      "|     3|      3|   3.0|964982304|\n",
      "|     3|      4|   5.0|964982134|\n",
      "|     4|      1|   2.0|964983234|\n",
      "|     4|      3|   4.0|964982923|\n",
      "|     4|      5|   3.0|964982891|\n",
      "|     5|      2|   3.0|964982634|\n",
      "|     5|      4|   4.0|964983456|\n",
      "|     5|      6|   5.0|964983567|\n",
      "|     6|      1|   4.0|964982765|\n",
      "|     6|      3|   2.0|964982876|\n",
      "|     6|      5|   3.0|964982987|\n",
      "|     7|      2|   5.0|964983098|\n",
      "|     7|      4|   3.0|964983209|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Recommendation System\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Path to the dataset (change this to the path where your dataset is stored)\n",
    "dataset_path = \"ratings.csv\"\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = spark.read.csv(dataset_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "df.show()\n",
    "\n",
    "# Print the schema of the DataFrame\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4211d455",
   "metadata": {},
   "source": [
    "2. Split the Data and Train a Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e1f5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Recommendation System\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset (assuming it's already loaded in the variable 'df')\n",
    "# For simplicity, we assume 'df' has columns 'userId', 'itemId', 'rating'\n",
    "# Split the data into training and test sets\n",
    "(training_data, test_data) = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Initialize the ALS model\n",
    "als = ALS(\n",
    "    maxIter=10,\n",
    "    regParam=0.01,\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model = als.fit(training_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb7d8b",
   "metadata": {},
   "source": [
    "3. Implement Collaborative Filtering with ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b327fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/31 14:43:10 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "24/08/31 14:43:10 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "24/08/31 14:43:10 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "24/08/31 14:43:10 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|    10|[{3, 2.9968333}, ...|\n",
      "|     1|[{1, 3.997205}, {...|\n",
      "|     2|[{1, 4.995301}, {...|\n",
      "|     3|[{4, 4.9967003}, ...|\n",
      "|     4|[{3, 3.9956493}, ...|\n",
      "|     5|[{6, 4.995433}, {...|\n",
      "|     6|[{5, 2.990452}, {...|\n",
      "|     7|[{2, 4.9963336}, ...|\n",
      "|     8|[{7, 3.9913669}, ...|\n",
      "|     9|[{4, 4.995452}, {...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Assuming 'training_data' is already split from the previous step\n",
    "\n",
    "# Initialize the ALS model\n",
    "als = ALS(\n",
    "    maxIter=10,\n",
    "    regParam=0.01,\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model = als.fit(training_data)\n",
    "\n",
    "# Save the model if needed\n",
    "model.save(\"model_pred\")\n",
    "\n",
    "# Generate recommendations\n",
    "user_recommendations = model.recommendForAllUsers(10)\n",
    "item_recommendations = model.recommendForAllItems(10)\n",
    "\n",
    "# Show recommendations for a few users\n",
    "user_recommendations.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce34dfb",
   "metadata": {},
   "source": [
    "4. Evaluate the Performance of the Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc905df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) = 2.9817852977302564\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Assuming 'predictions' DataFrame from the previous step\n",
    "\n",
    "# Initialize the RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) = {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390c1ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
