{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b0f787",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d60e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that a student is a hosteler given they scored A grade: 0.6923\n",
      "Probability of having the disease given a positive test result: 0.3333\n"
     ]
    }
   ],
   "source": [
    "def bayesTheorem(pA, pB, pBA):\n",
    "    return (pB * pBA) / pA\n",
    "\n",
    "# Problem a\n",
    "P_H = 0.60  # Probability of being a hosteler\n",
    "P_D = 0.40  # Probability of being a day scholar\n",
    "P_A_H = 0.30  # Probability of scoring A grade given hosteler\n",
    "P_A_D = 0.20  # Probability of scoring A grade given day scholar\n",
    "\n",
    "# Calculate P(A)\n",
    "P_A = (P_A_H * P_H) + (P_A_D * P_D)\n",
    "\n",
    "# Calculate P(H|A)\n",
    "P_H_A = bayesTheorem(P_A, P_H, P_A_H)\n",
    "print(f\"Probability that a student is a hosteler given they scored A grade: {P_H_A:.4f}\")\n",
    "\n",
    "# Problem b\n",
    "A = 0.01  # Prevalence of the disease (P_Disease)\n",
    "B = 0.99  # Sensitivity (P_Test_Positive_given_Disease)\n",
    "C = 0.02  # False positive rate (P_Test_Positive_given_NoDisease)\n",
    "A_bar = 1 - A  # Probability of not having the disease (P_No_Disease)\n",
    "\n",
    "# Calculate P(T)\n",
    "P_Test_Positive = (B * A) + (C * A_bar)\n",
    "\n",
    "# Calculate P(Disease|T)\n",
    "A_given_Test_Positive = bayesTheorem(P_Test_Positive, A, B)\n",
    "print(f\"Probability of having the disease given a positive test result: {A_given_Test_Positive:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed71c12",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "008f669d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.86\n",
      "Prediction for new data point: no\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.prior_probs = {}\n",
    "        self.likelihoods = {}\n",
    "        self.classes = []\n",
    "        self.features = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.features = X.columns\n",
    "        self.prior_probs = {cls: np.mean(y == cls) for cls in self.classes}\n",
    "        self.likelihoods = {cls: {} for cls in self.classes}\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            cls_data = X[y == cls]\n",
    "            for feature in self.features:\n",
    "                feature_values = cls_data[feature].value_counts(normalize=True)\n",
    "                self.likelihoods[cls][feature] = feature_values.to_dict()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for _, row in X.iterrows():\n",
    "            class_probs = {}\n",
    "            for cls in self.classes:\n",
    "                prior = self.prior_probs[cls]\n",
    "                likelihood = 1\n",
    "                for feature in self.features:\n",
    "                    feature_value = row[feature]\n",
    "                    if feature in self.likelihoods[cls] and feature_value in self.likelihoods[cls][feature]:\n",
    "                        likelihood *= self.likelihoods[cls][feature][feature_value]\n",
    "                    else:\n",
    "                        likelihood *= 1e-6  # Smoothing for unseen feature values\n",
    "                class_probs[cls] = prior * likelihood\n",
    "            predictions.append(max(class_probs, key=class_probs.get))\n",
    "        return predictions\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('buyers_data.csv')\n",
    "\n",
    "# Preprocess data\n",
    "df['buys_computer'] = df['buys_computer'].map({'yes': 'yes', 'no': 'no'})\n",
    "X = df.drop('buys_computer', axis=1)\n",
    "y = df['buys_computer']\n",
    "\n",
    "# Encode categorical features\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "nb_classifier = NaiveBayesClassifier()\n",
    "nb_classifier.fit(X_encoded, y)\n",
    "\n",
    "# Make predictions on the training data\n",
    "predictions = nb_classifier.predict(X_encoded)\n",
    "accuracy = np.mean(predictions == y)\n",
    "\n",
    "print(f\"Training Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Example prediction for a new data point\n",
    "new_data = pd.DataFrame({\n",
    "    'age': ['<=30'],\n",
    "    'income': ['high'],\n",
    "    'student': ['no'],\n",
    "    'credit_rating': ['fair']\n",
    "})\n",
    "\n",
    "new_data_encoded = pd.get_dummies(new_data)\n",
    "new_data_encoded = new_data_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
    "prediction = nb_classifier.predict(new_data_encoded)\n",
    "print(f\"Prediction for new data point: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c046f6f",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b745d071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision:\n",
      "  Not sports: 0.00\n",
      "  Sports: 0.00\n",
      "Recall:\n",
      "  Not sports: 0.00\n",
      "  Sports: 0.00\n",
      "Prediction for 'A very close game': Sports\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "class NaiveBayesTextClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_probs = {}\n",
    "        self.word_probs = {}\n",
    "        self.vocab = set()\n",
    "        self.classes = []\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        # Convert to lowercase and remove non-alphanumeric characters\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "        return text\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Get the classes and their prior probabilities\n",
    "        self.classes = np.unique(y)\n",
    "        class_counts = y.value_counts()\n",
    "        total_count = len(y)\n",
    "        self.class_probs = {cls: count / total_count for cls, count in class_counts.items()}\n",
    "        \n",
    "        # Initialize word counts\n",
    "        word_counts = {cls: Counter() for cls in self.classes}\n",
    "        class_word_counts = {cls: 0 for cls in self.classes}\n",
    "        \n",
    "        # Count words in each class\n",
    "        for text, cls in zip(X, y):\n",
    "            words = self.preprocess(text).split()\n",
    "            word_counts[cls].update(words)\n",
    "            class_word_counts[cls] += len(words)\n",
    "            self.vocab.update(words)\n",
    "        \n",
    "        # Calculate word probabilities with Laplace smoothing\n",
    "        self.word_probs = {cls: {} for cls in self.classes}\n",
    "        vocab_size = len(self.vocab)\n",
    "        for cls in self.classes:\n",
    "            total_words = class_word_counts[cls] + vocab_size\n",
    "            for word in self.vocab:\n",
    "                self.word_probs[cls][word] = (word_counts[cls][word] + 1) / total_words\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for text in X:\n",
    "            words = self.preprocess(text).split()\n",
    "            class_scores = {}\n",
    "            for cls in self.classes:\n",
    "                log_prob = np.log(self.class_probs[cls])\n",
    "                for word in words:\n",
    "                    if word in self.word_probs[cls]:\n",
    "                        log_prob += np.log(self.word_probs[cls][word])\n",
    "                    else:\n",
    "                        # Use a small probability for unknown words\n",
    "                        log_prob += np.log(1 / (class_word_counts[cls] + len(self.vocab)))\n",
    "                class_scores[cls] = log_prob\n",
    "            predictions.append(max(class_scores, key=class_scores.get))\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, X, y_true):\n",
    "        predictions = self.predict(X)\n",
    "        accuracy = np.mean(predictions == y_true)\n",
    "        precision, recall = {}, {}\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            true_positive = np.sum((predictions == cls) & (y_true == cls))\n",
    "            false_positive = np.sum((predictions == cls) & (y_true != cls))\n",
    "            false_negative = np.sum((predictions != cls) & (y_true == cls))\n",
    "            \n",
    "            precision[cls] = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "            recall[cls] = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "        \n",
    "        return accuracy, precision, recall\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('text_data.csv')\n",
    "\n",
    "# Prepare data\n",
    "X = df['Text']\n",
    "y = df['Tag']\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "nb_classifier = NaiveBayesTextClassifier()\n",
    "nb_classifier.fit(X, y)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall = nb_classifier.evaluate(X, y)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Precision:\")\n",
    "for cls, prec in precision.items():\n",
    "    print(f\"  {cls}: {prec:.2f}\")\n",
    "print(\"Recall:\")\n",
    "for cls, rec in recall.items():\n",
    "    print(f\"  {cls}: {rec:.2f}\")\n",
    "\n",
    "# Predict the tag for a new sentence\n",
    "new_sentence = [\"A very close game\"]\n",
    "prediction = nb_classifier.predict(new_sentence)\n",
    "print(f\"Prediction for '{new_sentence[0]}': {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e37e010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence \"A very close game\" is classified as: Sports\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    \"Text\": [\n",
    "        \"A great game\",\n",
    "        \"The election was over\",\n",
    "        \"Very clean match\",\n",
    "        \"A clean but forgettable game\",\n",
    "        \"It was a close election\"\n",
    "    ],\n",
    "    \"Tag\": [\n",
    "        \"Sports\",\n",
    "        \"Not sports\",\n",
    "        \"Sports\",\n",
    "        \"Sports\",\n",
    "        \"Not sports\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "df['Processed Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Initialize frequency tables\n",
    "word_counts = defaultdict(lambda: defaultdict(int))\n",
    "class_counts = defaultdict(int)\n",
    "total_docs = 0\n",
    "\n",
    "# Populate frequency tables\n",
    "for _, row in df.iterrows():\n",
    "    text = row['Processed Text']\n",
    "    tag = row['Tag']\n",
    "    \n",
    "    class_counts[tag] += 1\n",
    "    total_docs += 1\n",
    "    \n",
    "    for word in text:\n",
    "        word_counts[tag][word] += 1\n",
    "\n",
    "# Calculate class probabilities\n",
    "class_probs = {cls: count / total_docs for cls, count in class_counts.items()}\n",
    "\n",
    "# Calculate word probabilities\n",
    "def calculate_word_probs(word_counts, class_counts, total_docs):\n",
    "    word_probs = defaultdict(lambda: defaultdict(float))\n",
    "    vocab = set(word for word_counts_class in word_counts.values() for word in word_counts_class)\n",
    "\n",
    "    for cls, counts in word_counts.items():\n",
    "        total_words_in_class = sum(counts.values())\n",
    "        vocab_size = len(vocab)\n",
    "        for word in vocab:\n",
    "            word_probs[cls][word] = (counts.get(word, 0) + 1) / (total_words_in_class + vocab_size)\n",
    "    \n",
    "    return word_probs\n",
    "\n",
    "word_probs = calculate_word_probs(word_counts, class_counts, total_docs)\n",
    "\n",
    "# Classify new text\n",
    "def classify_text(text, class_probs, word_probs):\n",
    "    words = preprocess_text(text)\n",
    "    class_scores = {cls: math.log(prob) for cls, prob in class_probs.items()}\n",
    "    \n",
    "    for cls in class_probs:\n",
    "        for word in words:\n",
    "            if word in word_probs[cls]:\n",
    "                class_scores[cls] += math.log(word_probs[cls][word])\n",
    "    \n",
    "    return max(class_scores, key=class_scores.get)\n",
    "\n",
    "# Test the classifier with a new sentence\n",
    "new_sentence = \"A very close game\"\n",
    "tag = classify_text(new_sentence, class_probs, word_probs)\n",
    "print(f'The sentence \"{new_sentence}\" is classified as: {tag}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06bd7cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Occurrence Frequency Table by Class:\n",
      "             Sports  Not sports\n",
      "a                 2           1\n",
      "great             1           0\n",
      "game              2           0\n",
      "very              1           0\n",
      "clean             2           0\n",
      "match             1           0\n",
      "but               1           0\n",
      "forgettable       1           0\n",
      "the               0           1\n",
      "election          0           2\n",
      "was               0           2\n",
      "over              0           1\n",
      "it                0           1\n",
      "close             0           1\n",
      "\n",
      "Class Frequency Table:\n",
      "        Class  Count\n",
      "0      Sports      3\n",
      "1  Not sports      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    \"Text\": [\n",
    "        \"A great game\",\n",
    "        \"The election was over\",\n",
    "        \"Very clean match\",\n",
    "        \"A clean but forgettable game\",\n",
    "        \"It was a close election\"\n",
    "    ],\n",
    "    \"Tag\": [\n",
    "        \"Sports\",\n",
    "        \"Not sports\",\n",
    "        \"Sports\",\n",
    "        \"Sports\",\n",
    "        \"Not sports\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "df['Processed Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Initialize frequency tables\n",
    "word_counts = defaultdict(lambda: defaultdict(int))\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# Populate frequency tables\n",
    "for _, row in df.iterrows():\n",
    "    text = row['Processed Text']\n",
    "    tag = row['Tag']\n",
    "    \n",
    "    class_counts[tag] += 1\n",
    "    \n",
    "    for word in text:\n",
    "        word_counts[tag][word] += 1\n",
    "\n",
    "# Convert frequency tables to DataFrames for display\n",
    "word_counts_df = pd.DataFrame(word_counts).fillna(0).astype(int)\n",
    "class_counts_df = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Count'])\n",
    "\n",
    "# Display the frequency occurrence tables\n",
    "print(\"Word Occurrence Frequency Table by Class:\")\n",
    "print(word_counts_df)\n",
    "print(\"\\nClass Frequency Table:\")\n",
    "print(class_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab75963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
